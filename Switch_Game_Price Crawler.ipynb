{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import basic library\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library for mutiple threading\n",
    "import _thread\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filechecker function\n",
    "def filechecker(name):\n",
    "    data=pd.read_csv(name)\n",
    "    print('top 5 of',len(data),'rows from',name, 'data\\n',data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#swg_crawler function for creating brief info for switch games\n",
    "\n",
    "#global item_link\n",
    "item_link=[]\n",
    "def swg_crawler(link,filename='swg_brief.csv'):\n",
    "    response=requests.get(link)\n",
    "    soup=BeautifulSoup(response.text,'html.parser')\n",
    "    \n",
    "    games=soup.find_all('div',{'class':'cell'})\n",
    "    games\n",
    "    for game in games:\n",
    "        describe=game.find('div',{'class':'h6 name'}).text.strip()\n",
    "\n",
    "        try:\n",
    "            describe.split('\\n')[0]\n",
    "            name=describe.split('\\n')[0]\n",
    "        except:\n",
    "            name=[]\n",
    "            \n",
    "        try:\n",
    "            describe.split('\\n')[1]\n",
    "            discount=describe.split('\\n')[1]\n",
    "        except:\n",
    "            discount=[]\n",
    "            \n",
    "        try:\n",
    "            describe.split('\\n')[2]\n",
    "            tag=describe.split('\\n')[2]\n",
    "        except:\n",
    "            tag=[]\n",
    "            \n",
    "        try:\n",
    "            original_price=game.find('s',{'class':'text-muted'}).text.strip()\n",
    "        except:\n",
    "            original_price=[]\n",
    "            \n",
    "        try:\n",
    "            discount_price=game.find('strong').text.strip()\n",
    "        except:\n",
    "            discount_price=[]\n",
    "            \n",
    "        try:\n",
    "            deadline=game.find('div',{'class':'w-100'}).find('small').text.strip()\n",
    "        except:\n",
    "            deadline=[]\n",
    "            \n",
    "        \n",
    "        link=game.find('a',{'class':'main-link'})['href']\n",
    "        global item_link\n",
    "        item_link.append('https://www.dekudeals.com'+link)\n",
    "        \n",
    "        with open(filename,\"a+\",encoding='utf-8') as file:\n",
    "            writer = csv.writer(file, delimiter=',')\n",
    "            writer.writerow([name,discount,tag,original_price,discount_price,deadline])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#swg_crawler function for creating detail info for switch games\n",
    "\n",
    "def swg_item_crawler(link,filename='swg_detail.csv'):\n",
    "    response=requests.get(link)\n",
    "    soup=BeautifulSoup(response.text,'html.parser')\n",
    "    name=soup.find('span',{'class':'display-5'}).text\n",
    "    info=soup.find_all('li',{'class':'list-group-item'})\n",
    "    genre=[]\n",
    "    publisher=[]\n",
    "    size=[]\n",
    "    release_date=[]\n",
    "    metascore=[]\n",
    "    userscore=[]\n",
    "    language=[]\n",
    "    play_mode=[]\n",
    "    \n",
    "    for i in info:\n",
    "        if 'Genre' in i.text:\n",
    "            genre= i.text.split(': ')[1:]\n",
    "            #print(genre)\n",
    "        if 'Publisher' in i.text:\n",
    "            publisher=i.text.split(': ')[1:]\n",
    "            #print(publisher)\n",
    "        if 'Download' in i.text:\n",
    "            size=i.text.split(': ')[1:]\n",
    "            #print(size)\n",
    "        if 'Release' in i.text:\n",
    "            release_date=i.text.split(': ')[1:]\n",
    "            #print(release_date)\n",
    "        if 'Metacritic' in i.text:\n",
    "            metascore=i.text.split(' ')[1]\n",
    "            userscore=i.text.split(' ')[2]\n",
    "            #print(metascore)\n",
    "            #print(userscore)\n",
    "        if 'Language' in i.text:\n",
    "            language=i.text.split(': ')[1:]\n",
    "            #print(language)\n",
    "        if 'Play modes' in i.text:\n",
    "            play_mode=i.text.split(': ')[1:]\n",
    "            #print(play_mode)\n",
    "    stores=soup.find_all('tr',{'class':'table-primary'})\n",
    "    loc={}\n",
    "    for store in stores:\n",
    "        try:\n",
    "            store_loc=store.find('img')['alt']\n",
    "            version=store.find('td',{'class':'version'}).text.strip()\n",
    "            price,discount=(store.find('div',{'class','btn-primary'}).text.strip().split('\\n'))\n",
    "            loc.update({store_loc:[version,price,discount]})\n",
    "        except:\n",
    "            pass\n",
    "    #print(loc)\n",
    "    with open(filename,\"a+\",encoding='utf-8') as file:\n",
    "        writer = csv.writer(file, delimiter=',')\n",
    "        writer.writerow([name,genre,publisher,size,release_date,metascore,userscore,language,play_mode,loc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create header for files\n",
    "with open('swg_brief.csv',\"a+\",encoding='utf-8') as file:\n",
    "            writer = csv.writer(file, delimiter=',')\n",
    "            writer.writerow(['Name','Discount','Tag','Original_Price','Discount_Price','Deadline'])\n",
    "\n",
    "with open('swg_detail.csv',\"a+\",encoding='utf-8') as file:\n",
    "            writer = csv.writer(file, delimiter=',')\n",
    "            writer.writerow(['Name','Genre','Tag','Publisher','Download_Size','Release_Date','MetaScroe','UserScroe','Language','Play_Modes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the largest page number\n",
    "link='https://www.dekudeals.com/hottest?page=1'\n",
    "r=requests.get(link)\n",
    "soup=BeautifulSoup(r.text,'html5lib')\n",
    "maxpage=int(soup.find_all('a',{'class':'page-link'})[-2].text)+1\n",
    "maxpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.dekudeals.com/hottest?page=1',\n",
       " 'https://www.dekudeals.com/hottest?page=2',\n",
       " 'https://www.dekudeals.com/hottest?page=3',\n",
       " 'https://www.dekudeals.com/hottest?page=4',\n",
       " 'https://www.dekudeals.com/hottest?page=5',\n",
       " 'https://www.dekudeals.com/hottest?page=6',\n",
       " 'https://www.dekudeals.com/hottest?page=7',\n",
       " 'https://www.dekudeals.com/hottest?page=8',\n",
       " 'https://www.dekudeals.com/hottest?page=9',\n",
       " 'https://www.dekudeals.com/hottest?page=10',\n",
       " 'https://www.dekudeals.com/hottest?page=11',\n",
       " 'https://www.dekudeals.com/hottest?page=12',\n",
       " 'https://www.dekudeals.com/hottest?page=13',\n",
       " 'https://www.dekudeals.com/hottest?page=14',\n",
       " 'https://www.dekudeals.com/hottest?page=15',\n",
       " 'https://www.dekudeals.com/hottest?page=16']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main='https://www.dekudeals.com/'\n",
    "link_list=[]\n",
    "for i in range(1,maxpage):\n",
    "    link_list.append(main+'hottest?page='+str(i))\n",
    "link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.061360836029053 secs spend to craw these 16 pages\n",
      "top 5 of 558 rows from swg_brief.csv data\n",
      "                                         Name Discount                   Tag  \\\n",
      "0                  Tower of Babel - no mercy     -80%     Lowest price ever   \n",
      "1  LEGO Marvel Super Heroes 2 Deluxe Edition     -70%  Matches previous low   \n",
      "2                                 1-2-Switch     -28%                    []   \n",
      "3                        Stick It to The Man     -80%  Matches previous low   \n",
      "4                      Wide Ocean Big Jacket     -60%  Matches previous low   \n",
      "\n",
      "  Original_Price Discount_Price              Deadline  \n",
      "0          $9.99          $1.99  Sale ends in 7 hours  \n",
      "1         $44.99         $13.49  Sale ends November 2  \n",
      "2         $49.99         $35.88                    []  \n",
      "3         $11.99          $2.39  Sale ends November 1  \n",
      "4          $7.99          $3.19  Sale ends November 1  \n"
     ]
    }
   ],
   "source": [
    "threads=[]\n",
    "#build all the tasks \n",
    "for link in link_list:\n",
    "    thread = threading.Thread(target=swg_crawler,args=(link,'swg_brief.csv'))\n",
    "    threads.append(thread) \n",
    " \n",
    "                              \n",
    "startTime=time.time()                              \n",
    "#start all the tasks at once\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "    \n",
    "#wait for all the tasks to finish\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "                              \n",
    "finishTime = time.time()\n",
    "print(finishTime - startTime,'secs spend to craw these {0} pages'.format(len(link_list)))\n",
    "\n",
    "      \n",
    "filechecker('swg_brief.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
