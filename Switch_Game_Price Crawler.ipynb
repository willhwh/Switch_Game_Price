{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filechecker(name):\n",
    "    data=pd.read_csv(name)\n",
    "    print('top 5 of',len(data),'rows from',name, 'data\\n',data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single thread crawler\n",
    "- the first 3 pages of switch game price info. in hottest order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.412523031234741 secs spend to craw these 3 pages\n",
      "top 5 of 108 rows from sgp_first3.csv data\n",
      "                                           Name Discount                   Tag  \\\n",
      "0        Tales of Vesperia: Definitive Edition     -60%  Matches previous low   \n",
      "1  Mario + Rabbids Kingdom Battle Gold Edition     -75%  Matches previous low   \n",
      "2                      DRAGON BALL Xenoverse 2     -80%     Lowest price ever   \n",
      "3          Monster Hunter Generations Ultimate     -60%  Matches previous low   \n",
      "4                Trine 4: The Nightmare Prince     -60%     Lowest price ever   \n",
      "\n",
      "  Original_Price Discount_Price          Deadline  \n",
      "0         $49.99         $19.99  Sale ends May 26  \n",
      "1         $79.99         $19.99  Sale ends May 26  \n",
      "2         $49.99          $9.99  Sale ends May 26  \n",
      "3         $49.99         $19.99  Sale ends May 27  \n",
      "4         $29.99         $11.99  Sale ends May 26  \n"
     ]
    }
   ],
   "source": [
    "with open('sgp_first3.csv',\"a+\",encoding='utf-8') as file:\n",
    "            writer = csv.writer(file, delimiter=',')\n",
    "            writer.writerow(['Name','Discount','Tag','Original_Price','Discount_Price','Deadline'])\n",
    "\n",
    "\n",
    "\n",
    "main='https://www.dekudeals.com/'\n",
    "link_list=[]\n",
    "headers={'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36'}\n",
    "for i in range(1,4):\n",
    "    link_list.append(main+'hottest?page='+str(i))\n",
    "    \n",
    "startTime=time.time()\n",
    "for link in link_list:\n",
    "    response=requests.get(link,headers=headers)\n",
    "    soup=BeautifulSoup(response.text,'html.parser')\n",
    "    \n",
    "    games=soup.find_all('div',{'class':'cell'})\n",
    "    games\n",
    "    for game in games:\n",
    "        describe=game.find('div',{'class':'h6 name'}).text.strip()\n",
    "        name=[]\n",
    "        discount=[]\n",
    "        tag=[]\n",
    "        original_price=[]\n",
    "        discount_price=[]\n",
    "        deadline=[]\n",
    "        try:\n",
    "            describe.split('\\n')[0]\n",
    "            name=describe.split('\\n')[0]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            describe.split('\\n')[1]\n",
    "            discount=describe.split('\\n')[1]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            describe.split('\\n')[2]\n",
    "            tag=describe.split('\\n')[2]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            original_price=game.find('s',{'class':'text-muted'}).text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            discount_price=game.find('strong').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            deadline=game.find('div',{'class':'w-100'}).find('small').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        with open('sgp_first3.csv',\"a+\",encoding='utf-8') as file:\n",
    "            writer = csv.writer(file, delimiter=',')\n",
    "            writer.writerow([name,discount,tag,original_price,discount_price,deadline])\n",
    "            \n",
    "finishTime = time.time()\n",
    "print(finishTime - startTime,'secs spend to craw these 3 pages')\n",
    "filechecker('sgp_first3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use proxy\n",
    "- the number 4-6 pages of switch game price info. in hottest order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "300 proxy in pool\n",
      "3 useble ip: ['68.183.208.248:80', '80.211.210.39:8080', '149.28.104.226:3128']\n"
     ]
    }
   ],
   "source": [
    "# get three proxy from link:  https://free-proxy-list.net/ \n",
    "url='https://free-proxy-list.net/'\n",
    "r=requests.get(url)\n",
    "print(r)\n",
    "soup=BeautifulSoup(r.text,'html5lib')\n",
    "ip_lst=[]\n",
    "n=0\n",
    "for i in soup.find('tbody').find_all('tr'):\n",
    "    n=n+1\n",
    "    ip=i.find('td').text\n",
    "    port=i.find_all('td')[1].text\n",
    "    ip_lst.append(i.find('td').text+':'+port)\n",
    "print(len(ip_lst),'proxy in pool')\n",
    "\n",
    "n=0\n",
    "useble_lst=[]\n",
    "for ip in ip_lst:\n",
    "    if n<3:\n",
    "        try:\n",
    "            resp = requests.get('http://ip.filefab.com/index.php',proxies={'http': ip})\n",
    "            soup = BeautifulSoup(resp.text, 'html5lib')\n",
    "            useble_lst.append(ip)\n",
    "            n=n+1\n",
    "        except:\n",
    "            continue\n",
    "print('3 useble ip:',useble_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4789209365844727 secs spend to craw these 3 pages\n",
      "top 5 of 108 rows from sgp_4-6.csv data\n",
      "                                         Name Discount                   Tag  \\\n",
      "0  Starlink: Battle for Atlas – Starter Pack     -71%                    []   \n",
      "1                              Syberia 1 & 2     -66%  Matches previous low   \n",
      "2    DRAGON BALL FIGHTERZ - Ultimate Edition     -75%  Matches previous low   \n",
      "3                            Thief Simulator     -90%  Matches previous low   \n",
      "4                               Bomb Chicken     -50%  Matches previous low   \n",
      "\n",
      "  Original_Price Discount_Price               Deadline  \n",
      "0         $74.99         $21.97                     []  \n",
      "1         $34.99         $12.00  Sale ends in 15 hours  \n",
      "2        $109.99         $27.49       Sale ends May 26  \n",
      "3         $19.99          $1.99       Sale ends May 27  \n",
      "4         $14.99          $7.49       Sale ends May 24  \n"
     ]
    }
   ],
   "source": [
    "with open('sgp_4-6.csv',\"a+\",encoding='utf-8') as file:\n",
    "            writer = csv.writer(file, delimiter=',')\n",
    "            writer.writerow(['Name','Discount','Tag','Original_Price','Discount_Price','Deadline'])\n",
    "\n",
    "main='https://www.dekudeals.com/'\n",
    "link_list=[]\n",
    "headers={'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36'}\n",
    "for i in range(4,7):\n",
    "    link_list.append(main+'hottest?page='+str(i))\n",
    "    \n",
    "startTime=time.time()\n",
    "for link,ip in zip(link_list,useble_lst):\n",
    "    response=requests.get(link,headers=headers,proxies={'http': ip})\n",
    "    soup=BeautifulSoup(response.text,'html.parser')\n",
    "    \n",
    "    games=soup.find_all('div',{'class':'cell'})\n",
    "    games\n",
    "    for game in games:\n",
    "        describe=game.find('div',{'class':'h6 name'}).text.strip()\n",
    "        name=[]\n",
    "        discount=[]\n",
    "        tag=[]\n",
    "        original_price=[]\n",
    "        discount_price=[]\n",
    "        deadline=[]\n",
    "        try:\n",
    "            describe.split('\\n')[0]\n",
    "            name=describe.split('\\n')[0]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            describe.split('\\n')[1]\n",
    "            discount=describe.split('\\n')[1]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            describe.split('\\n')[2]\n",
    "            tag=describe.split('\\n')[2]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            original_price=game.find('s',{'class':'text-muted'}).text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            discount_price=game.find('strong').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            deadline=game.find('div',{'class':'w-100'}).find('small').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        with open('sgp_4-6.csv',\"a+\",encoding='utf-8') as file:\n",
    "            writer = csv.writer(file, delimiter=',')\n",
    "            writer.writerow([name,discount,tag,original_price,discount_price,deadline])\n",
    "            \n",
    "finishTime = time.time()\n",
    "print(finishTime - startTime,'secs spend to craw these 3 pages')\n",
    "\n",
    "filechecker('sgp_4-6.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutiple thread\n",
    "-3thread for crawlering the number 7-9 pages of switch game price info. in hottest order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swg_crawler(link_list,filename):\n",
    "    with open(filename,\"a+\",encoding='utf-8') as file:\n",
    "            writer = csv.writer(file, delimiter=',')\n",
    "            writer.writerow(['Name','Discount','Tag','Original_Price','Discount_Price','Deadline'])\n",
    "    \n",
    "    for link in link_list:\n",
    "        response=requests.get(link)\n",
    "        soup=BeautifulSoup(response.text,'html.parser')\n",
    "    \n",
    "        games=soup.find_all('div',{'class':'cell'})\n",
    "        games\n",
    "        for game in games:\n",
    "            describe=game.find('div',{'class':'h6 name'}).text.strip()\n",
    "            name=[]\n",
    "            discount=[]\n",
    "            tag=[]\n",
    "            original_price=[]\n",
    "            discount_price=[]\n",
    "            deadline=[]\n",
    "            try:\n",
    "                describe.split('\\n')[0]\n",
    "                name=describe.split('\\n')[0]\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                describe.split('\\n')[1]\n",
    "                discount=describe.split('\\n')[1]\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                describe.split('\\n')[2]\n",
    "                tag=describe.split('\\n')[2]\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                original_price=game.find('s',{'class':'text-muted'}).text.strip()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                discount_price=game.find('strong').text.strip()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                deadline=game.find('div',{'class':'w-100'}).find('small').text.strip()\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "            with open(filename,\"a+\",encoding='utf-8') as file:\n",
    "                writer = csv.writer(file, delimiter=',')\n",
    "                writer.writerow([name,discount,tag,original_price,discount_price,deadline])\n",
    "    \n",
    "    filechecker(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['https://www.dekudeals.com/hottest?page=7', 'https://www.dekudeals.com/hottest?page=8', 'https://www.dekudeals.com/hottest?page=9'], ['https://www.dekudeals.com/hottest?page=10', 'https://www.dekudeals.com/hottest?page=11']]\n"
     ]
    }
   ],
   "source": [
    "link_list7=[]\n",
    "link_list9=[]\n",
    "link_list_large=[]\n",
    "for i in range(7,10):\n",
    "    link_list7.append(main+'hottest?page='+str(i))\n",
    "for i in range(10,12):\n",
    "    link_list9.append(main+'hottest?page='+str(i))\n",
    "\n",
    "link_list_large.append(link_list7)\n",
    "link_list_large.append(link_list9)\n",
    "\n",
    "print(link_list_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003299713134765625 secs spend to craw these 5 pages\n"
     ]
    }
   ],
   "source": [
    "startTime=time.time()\n",
    "\n",
    "for link_list,n in zip(link_list_large,[7,9]):\n",
    "    _thread.start_new_thread(swg_crawler,(link_list,'sgp_{0}.csv'.format(str(n)) ))\n",
    "    \n",
    "finishTime = time.time()\n",
    "print(finishTime - startTime,'secs spend to craw these 5 pages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asynchronous Crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp \n",
    "import asyncio \n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the largest page number\n",
    "link='https://www.dekudeals.com/hottest?page=1'\n",
    "r=requests.get(link)\n",
    "soup=BeautifulSoup(r.text,'html5lib')\n",
    "maxpage=int(soup.find_all('a',{'class':'page-link'})[-2].text)+1\n",
    "maxpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swg_crawler_single(link,filename='asyncio.csv'):\n",
    "    response=requests.get(link)\n",
    "    soup=BeautifulSoup(response.text,'html.parser')\n",
    "    \n",
    "    games=soup.find_all('div',{'class':'cell'})\n",
    "    games\n",
    "    for game in games:\n",
    "        describe=game.find('div',{'class':'h6 name'}).text.strip()\n",
    "        name=[]\n",
    "        discount=[]\n",
    "        tag=[]\n",
    "        original_price=[]\n",
    "        discount_price=[]\n",
    "        deadline=[]\n",
    "        try:\n",
    "            describe.split('\\n')[0]\n",
    "            name=describe.split('\\n')[0]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            describe.split('\\n')[1]\n",
    "            discount=describe.split('\\n')[1]\n",
    "        except:\n",
    "              pass\n",
    "        try:\n",
    "            describe.split('\\n')[2]\n",
    "            tag=describe.split('\\n')[2]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            original_price=game.find('s',{'class':'text-muted'}).text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            discount_price=game.find('strong').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            deadline=game.find('div',{'class':'w-100'}).find('small').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "        with open(filename,\"a+\",encoding='utf-8') as file:\n",
    "            writer = csv.writer(file, delimiter=',')\n",
    "            writer.writerow([name,discount,tag,original_price,discount_price,deadline])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Async total time :  13.381500005722046\n",
      "top 5 of 387 rows from asyncio.csv data\n",
      "                                           Name Discount                   Tag  \\\n",
      "0        Tales of Vesperia: Definitive Edition     -60%  Matches previous low   \n",
      "1  Mario + Rabbids Kingdom Battle Gold Edition     -75%  Matches previous low   \n",
      "2                      DRAGON BALL Xenoverse 2     -80%     Lowest price ever   \n",
      "3          Monster Hunter Generations Ultimate     -60%  Matches previous low   \n",
      "4                Trine 4: The Nightmare Prince     -60%     Lowest price ever   \n",
      "\n",
      "  Original_Price Discount_Price          Deadline  \n",
      "0         $49.99         $19.99  Sale ends May 26  \n",
      "1         $79.99         $19.99  Sale ends May 26  \n",
      "2         $49.99          $9.99  Sale ends May 26  \n",
      "3         $49.99         $19.99  Sale ends May 27  \n",
      "4         $29.99         $11.99  Sale ends May 26  \n"
     ]
    }
   ],
   "source": [
    "with open('asyncio.csv',\"a+\",encoding='utf-8') as file:\n",
    "            writer = csv.writer(file, delimiter=',')\n",
    "            writer.writerow(['Name','Discount','Tag','Original_Price','Discount_Price','Deadline'])\n",
    "\n",
    "main='https://www.dekudeals.com/'\n",
    "link_list=[]\n",
    "for i in range(1,maxpage):\n",
    "    link_list.append(main+'hottest?page='+str(i)) \n",
    "    \n",
    "n=0\n",
    "async def job(link):                   # async 形式的功能\n",
    "    swg_crawler_single(link)\n",
    "    await asyncio.sleep(0)           #等待數秒並切換  #也可移除表不等待\n",
    "    \n",
    "\n",
    "async def main(loop):                       # async 形式的功能\n",
    "    tasks = [loop.create_task(job(link)) for link in link_list]    # 創建任務, 但是不執行\n",
    "    await asyncio.wait(tasks)               # 執行並等待所有任務完成\n",
    "\n",
    "startTime = time.time()\n",
    "loop = asyncio.get_event_loop()             # 建立 loop\n",
    "loop.run_until_complete(main(loop))         # 執行 loop                        \n",
    "#loop.close() #關閉 loop\n",
    "finishTime=time.time()\n",
    "print(\"Async total time : \", finishTime - startTime)\n",
    "filechecker('asyncio.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single time :  11.486860990524292\n",
      "top 5 of 387 rows from single.csv data\n",
      "                                           Name Discount                   Tag  \\\n",
      "0        Tales of Vesperia: Definitive Edition     -60%  Matches previous low   \n",
      "1  Mario + Rabbids Kingdom Battle Gold Edition     -75%  Matches previous low   \n",
      "2                      DRAGON BALL Xenoverse 2     -80%     Lowest price ever   \n",
      "3          Monster Hunter Generations Ultimate     -60%  Matches previous low   \n",
      "4                Trine 4: The Nightmare Prince     -60%     Lowest price ever   \n",
      "\n",
      "  Original_Price Discount_Price          Deadline  \n",
      "0         $49.99         $19.99  Sale ends May 26  \n",
      "1         $79.99         $19.99  Sale ends May 26  \n",
      "2         $49.99          $9.99  Sale ends May 26  \n",
      "3         $49.99         $19.99  Sale ends May 27  \n",
      "4         $29.99         $11.99  Sale ends May 26  \n"
     ]
    }
   ],
   "source": [
    "with open('single.csv',\"a+\",encoding='utf-8') as file:\n",
    "            writer = csv.writer(file, delimiter=',')\n",
    "            writer.writerow(['Name','Discount','Tag','Original_Price','Discount_Price','Deadline'])\n",
    "            \n",
    "main='https://www.dekudeals.com/'\n",
    "link_list=[]\n",
    "for i in range(1,maxpage):\n",
    "    link_list.append(main+'hottest?page='+str(i)) \n",
    "\n",
    "startTime=time.time()    \n",
    "for link in link_list:\n",
    "    swg_crawler_single(link,filename='single.csv')\n",
    "    \n",
    "    \n",
    "finishTime=time.time()\n",
    "print(\"Single time : \", finishTime - startTime)\n",
    "filechecker('single.csv')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutiple thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.555413007736206 secs spend to craw these 11 pages\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'filechecker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-6002d67136fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mfinishTime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinishTime\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstartTime\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'secs spend to craw these 11 pages'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mfilechecker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'muti_thread.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'filechecker' is not defined"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "with open('muti_thread.csv',\"a+\",encoding='utf-8') as file:\n",
    "            writer = csv.writer(file, delimiter=',')\n",
    "            writer.writerow(['Name','Discount','Tag','Original_Price','Discount_Price','Deadline'])\n",
    "\n",
    "main='https://www.dekudeals.com/'\n",
    "link_list=[]\n",
    "for i in range(1,maxpage):\n",
    "    link_list.append(main+'hottest?page='+str(i)) \n",
    "\n",
    "\n",
    "startTime=time.time()\n",
    "\n",
    "threads=[]\n",
    "#build all the tasks \n",
    "for link in link_list:\n",
    "    thread = threading.Thread(target=swg_crawler_single,args=(link,'muti_thread.csv'))\n",
    "    threads.append(thread) \n",
    "    \n",
    "#start all the tasks at once\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "    \n",
    "#wait for all the tasks to finish\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "    \n",
    "finishTime = time.time()\n",
    "print(finishTime - startTime,'secs spend to craw these 11 pages')\n",
    "filechecker('muti_thread.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save game photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 389 images saved\n"
     ]
    }
   ],
   "source": [
    "# path\n",
    "output_dir = 'image'\n",
    "\n",
    "# if not exist, create one\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "#link list\n",
    "main='https://www.dekudeals.com/'\n",
    "link_list=[]\n",
    "for i in range(1,maxpage):\n",
    "    link_list.append(main+'hottest?page='+str(i))     \n",
    "\n",
    "n=0 \n",
    "for link in link_list:\n",
    "   \n",
    "    #image_tag\n",
    "    response=requests.get(link)\n",
    "    soup=BeautifulSoup(response.text,'html.parser')\n",
    "    items=soup.find_all('div',{'class':'col-xl-2'})\n",
    "    for item in items:\n",
    "        try:\n",
    "            describe=item.find('div',{'class':'name'}).text.strip()\n",
    "            name=describe.split('\\n')[0].replace('/',',')\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        image_link=item.find('div',{'class':'tiny'}).find('img')['src']\n",
    "    \n",
    "        with requests.get(image_link, stream=True) as r:\n",
    "            n=n+1\n",
    "            r.raise_for_status()#check status\n",
    "            # check format\n",
    "            img = Image.open(r.raw)#format\n",
    "            img_savename = '{outdir}/{img_id}.{img_ext}'.format(\n",
    "                outdir=output_dir, img_id=name, img_ext=img.format.lower())\n",
    "            img.save(img_savename)\n",
    "        #print('Save image {}'.format(img_savename))\n",
    "print('Total',n,'images saved')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 of 389 game images\n",
      " ['Sparklite.jpeg', 'Cars 3: Driven to Win.jpeg', 'Little Dragons Café Limited Edition.jpeg', 'Little Dragons Café.jpeg', 'The Witcher 3: Wild Hunt — Complete Edition.jpeg']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "imagefiles = []\n",
    "for file in glob.glob(\"image/*.jpeg\"):\n",
    "    imagefiles.append(file.replace('image/',''))\n",
    "for file in glob.glob('image/*.png'):\n",
    "    imagefiles.append(file.replace('image/',''))\n",
    "\n",
    "print('Top 5 of {0} game images\\n'.format(len(imagefiles)),imagefiles[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all the options for searching game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome(executable_path='chromedriver')\n",
    "browser.get(\"https://www.dekudeals.com/hottest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hottest deals': '?sort=hottest',\n",
       " 'Name': '?sort=name',\n",
       " 'Price': '?sort=price',\n",
       " 'Discount %': '?sort=discount',\n",
       " 'Discount amount': '?sort=discount_amount',\n",
       " 'Release date': '?sort=release_date',\n",
       " 'Most wanted': '?sort=most_wanted',\n",
       " 'Most owned': '?sort=most_owned',\n",
       " 'Metacritic (metascore)': '?sort=metacritic',\n",
       " 'Metacritic (user score)': '?sort=metacritic_user',\n",
       " 'Sale end date': '?sort=ends_at',\n",
       " 'Game length': '?sort=game_length',\n",
       " 'Added to site': '?sort=added_to_site',\n",
       " 'Bang for your buck': '?sort=bang_per_buck'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_source = browser.page_source\n",
    "soup=BeautifulSoup(html_source,'html.parser')\n",
    "sorts=soup.find_all('a',{'class':'dropdown-item'})\n",
    "sort_list={}\n",
    "for sort in sorts:\n",
    "    sort_list.update({sort.text:sort['href']})\n",
    "sort_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.dekudeals.com/hottest?sort=hottest\n",
      "In Hottest deals type the top 5 game:['Tales of Vesperia: Definitive Edition', 'Mario + Rabbids Kingdom Battle Gold Edition', 'DRAGON BALL Xenoverse 2', 'Monster Hunter Generations Ultimate', 'Trine 4: The Nightmare Prince']\n",
      "\n",
      "https://www.dekudeals.com/hottest?sort=name\n",
      "In Name type the top 5 game:['3000th Duel', '39 Days to Mars', '88 Heroes - 98 Heroes Edition', 'A Case of Distrust', 'A Normal Lost Phone']\n",
      "\n",
      "https://www.dekudeals.com/hottest?sort=price\n",
      "In Price type the top 5 game:['Akane', 'Bury me, my Love', 'Mana Spark', 'Saturday Morning RPG', 'Cosmic Star Heroine']\n",
      "\n",
      "https://www.dekudeals.com/hottest?sort=discount\n",
      "In Discount % type the top 5 game:['Mana Spark', 'Saturday Morning RPG', 'Cosmic Star Heroine', 'INVERSUS Deluxe', 'My Brother Rabbit']\n",
      "\n",
      "https://www.dekudeals.com/hottest?sort=discount_amount\n",
      "In Discount amount type the top 5 game:['Darksiders Genesis - Nephilim Edition ', 'DRAGON BALL FIGHTERZ - Ultimate Edition', 'DRAGON BALL FIGHTERZ - FighterZ Edition', 'Mario + Rabbids Kingdom Battle Gold Edition', 'Starlink: Battle for Atlas – Starter Pack']\n",
      "\n",
      "https://www.dekudeals.com/hottest?sort=release_date\n",
      "In Release date type the top 5 game:['Darksiders Genesis - Nephilim Edition ', 'Immortal Realms: Vampire Wars', 'Liberated', 'realMyst: Masterpiece Edition', 'WHAT THE GOLF?']\n",
      "\n",
      "https://www.dekudeals.com/hottest?sort=most_wanted\n",
      "In Most wanted type the top 5 game:['Super Mario Odyssey', 'Donkey Kong Country: Tropical Freeze', 'The Legend of Zelda: Breath of the Wild', 'The Witcher 3: Wild Hunt — Complete Edition', 'Super Mario Party']\n",
      "\n",
      "https://www.dekudeals.com/hottest?sort=most_owned\n",
      "In Most owned type the top 5 game:['The Legend of Zelda: Breath of the Wild', 'Super Mario Odyssey', 'Mario + Rabbids Kingdom Battle', 'Super Mario Party', 'Diablo III: Eternal Collection']\n",
      "\n",
      "https://www.dekudeals.com/hottest?sort=metacritic\n",
      "In Metacritic (metascore) type the top 5 game:['Super Mario Odyssey', 'The Legend of Zelda: Breath of the Wild', 'Shovel Knight: Treasure Trove', 'Florence', 'Cave Story+']\n",
      "\n",
      "https://www.dekudeals.com/hottest?sort=metacritic_user\n",
      "In Metacritic (user score) type the top 5 game:['Umihara Kawase Fresh!', 'Super Mario Odyssey', 'Donkey Kong Country: Tropical Freeze', 'FINAL FANTASY XII THE ZODIAC AGE', 'Xenoblade Chronicles 2: Torna ~ The Golden Country']\n",
      "\n",
      "https://www.dekudeals.com/hottest?sort=ends_at\n",
      "In Sale end date type the top 5 game:['88 Heroes - 98 Heroes Edition', 'X-Morph: Defense Complete Edition', 'Trailblazers', 'X-Morph: Defense', 'Gun Gun Pixies']\n",
      "\n",
      "https://www.dekudeals.com/hottest?sort=game_length\n",
      "In Game length type the top 5 game:['Dragon Blaze', 'STRIKERS1945 II', 'Florence', 'STRIKERS1945', \"Johnny Turbo's Arcade Joe and Mac Caveman Ninja\"]\n",
      "\n",
      "https://www.dekudeals.com/hottest?sort=added_to_site\n",
      "In Added to site type the top 5 game:['realMyst: Masterpiece Edition', 'Slayin 2', 'Telling Lies', 'Piczle Cross Adventure', 'Fury Unleashed']\n",
      "\n",
      "https://www.dekudeals.com/hottest?sort=bang_per_buck\n",
      "In Bang for your buck type the top 5 game:['Monster Hunter Generations Ultimate', 'Overwatch: Legendary Edition', 'Cosmic Star Heroine', 'Mana Spark', 'Regalia: Of Men and Monarchs - Royal Edition']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sort in sort_list:\n",
    "    browser.get(\"https://www.dekudeals.com/hottest{0}\".format(sort_list.get(sort)))\n",
    "    html_source = browser.page_source\n",
    "    print(browser.current_url)\n",
    "    soup=BeautifulSoup(html_source,'html.parser')\n",
    "    games=soup.find_all('div',{'class':'cell'})[:5]\n",
    "    game_list=[]\n",
    "    for game in games:\n",
    "        describe=game.find('div',{'class':'h6 name'}).text.strip()\n",
    "        name=[]\n",
    "        discount=[]\n",
    "        tag=[]\n",
    "        original_price=[]\n",
    "        discount_price=[]\n",
    "        deadline=[]\n",
    "        try:\n",
    "            describe.split('\\n')[0]\n",
    "            name=describe.split('\\n')[0]\n",
    "        except:\n",
    "            pass\n",
    "        game_list.append(name)\n",
    "    print('In {0} type the top 5 game:{1}\\n'.format(sort,game_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
