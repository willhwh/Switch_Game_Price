{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filechecker(name):\n",
    "    data=pd.read_csv(name)\n",
    "    print('top 5 of',len(data),'rows from',name, 'data\\n',data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single thread crawler\n",
    "- the first 3 pages of switch game price info. in hottest order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1085360050201416 secs spend to craw these 3 pages\n",
      "top 5 of 217 rows from sgp_first3.csv data\n",
      "                                       Name Discount                   Tag  \\\n",
      "0                              Moonlighter     -66%  Matches previous low   \n",
      "1  Ghostbusters: The Video Game Remastered     -75%     Lowest price ever   \n",
      "2                                Cat Quest     -85%     Lowest price ever   \n",
      "3                               Bloodroots     -90%     Lowest price ever   \n",
      "4                 BioShock: The Collection     -40%     Lowest price ever   \n",
      "\n",
      "  Original_Price Discount_Price               Deadline  \n",
      "0         $24.99          $8.49   Sale ends October 31  \n",
      "1         $29.99          $7.49   Sale ends November 2  \n",
      "2         $12.99          $1.99  Sale ends in 38 hours  \n",
      "3         $19.99          $1.99   Sale ends November 2  \n",
      "4         $49.99         $29.83                     []  \n"
     ]
    }
   ],
   "source": [
    "with open('sgp_first3.csv',\"a+\",encoding='utf-8') as file:\n",
    "            writer = csv.writer(file, delimiter=',')\n",
    "            writer.writerow(['Name','Discount','Tag','Original_Price','Discount_Price','Deadline'])\n",
    "\n",
    "\n",
    "\n",
    "main='https://www.dekudeals.com/'\n",
    "link_list=[]\n",
    "headers={'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36'}\n",
    "for i in range(1,4):\n",
    "    link_list.append(main+'hottest?page='+str(i))\n",
    "    \n",
    "startTime=time.time()\n",
    "for link in link_list:\n",
    "    response=requests.get(link,headers=headers)\n",
    "    soup=BeautifulSoup(response.text,'html.parser')\n",
    "    \n",
    "    games=soup.find_all('div',{'class':'cell'})\n",
    "    games\n",
    "    for game in games:\n",
    "        describe=game.find('div',{'class':'h6 name'}).text.strip()\n",
    "        name=[]\n",
    "        discount=[]\n",
    "        tag=[]\n",
    "        original_price=[]\n",
    "        discount_price=[]\n",
    "        deadline=[]\n",
    "        try:\n",
    "            describe.split('\\n')[0]\n",
    "            name=describe.split('\\n')[0]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            describe.split('\\n')[1]\n",
    "            discount=describe.split('\\n')[1]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            describe.split('\\n')[2]\n",
    "            tag=describe.split('\\n')[2]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            original_price=game.find('s',{'class':'text-muted'}).text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            discount_price=game.find('strong').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            deadline=game.find('div',{'class':'w-100'}).find('small').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        with open('sgp_first3.csv',\"a+\",encoding='utf-8') as file:\n",
    "            writer = csv.writer(file, delimiter=',')\n",
    "            writer.writerow([name,discount,tag,original_price,discount_price,deadline])\n",
    "            \n",
    "finishTime = time.time()\n",
    "print(finishTime - startTime,'secs spend to craw these 3 pages')\n",
    "filechecker('sgp_first3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use proxy\n",
    "- the number 4-6 pages of switch game price info. in hottest order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "300 proxy in pool\n",
      "3 useble ip: ['78.96.125.24:3128', '103.143.46.27:80', '43.248.24.157:51166']\n"
     ]
    }
   ],
   "source": [
    "# get three proxy from link:  https://free-proxy-list.net/ \n",
    "url='https://free-proxy-list.net/'\n",
    "r=requests.get(url)\n",
    "print(r)\n",
    "soup=BeautifulSoup(r.text,'html5lib')\n",
    "ip_lst=[]\n",
    "n=0\n",
    "for i in soup.find('tbody').find_all('tr'):\n",
    "    n=n+1\n",
    "    ip=i.find('td').text\n",
    "    port=i.find_all('td')[1].text\n",
    "    ip_lst.append(i.find('td').text+':'+port)\n",
    "print(len(ip_lst),'proxy in pool')\n",
    "\n",
    "n=0\n",
    "useble_lst=[]\n",
    "for ip in ip_lst:\n",
    "    if n<3:\n",
    "        try:\n",
    "            resp = requests.get('http://ip.filefab.com/index.php',proxies={'http': ip})\n",
    "            soup = BeautifulSoup(resp.text, 'html5lib')\n",
    "            useble_lst.append(ip)\n",
    "            n=n+1\n",
    "        except:\n",
    "            continue\n",
    "print('3 useble ip:',useble_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2331178188323975 secs spend to craw these 3 pages\n",
      "top 5 of 217 rows from sgp_4-6.csv data\n",
      "                            Name Discount                   Tag Original_Price  \\\n",
      "0  ONE PIECE: PIRATE WARRIORS 4     -50%     Lowest price ever         $59.99   \n",
      "1                       Deponia     -90%  Matches previous low         $39.99   \n",
      "2         The Long Journey Home     -80%     Lowest price ever         $29.99   \n",
      "3             Octopath Traveler     -17%                    []         $59.99   \n",
      "4                   AO Tennis 2     -83%     Lowest price ever         $59.99   \n",
      "\n",
      "  Discount_Price               Deadline  \n",
      "0         $29.99                     []  \n",
      "1          $3.99  Sale ends November 11  \n",
      "2          $5.99  Sale ends November 11  \n",
      "3         $49.94                     []  \n",
      "4          $9.99                     []  \n"
     ]
    }
   ],
   "source": [
    "with open('sgp_4-6.csv',\"a+\",encoding='utf-8') as file:\n",
    "            writer = csv.writer(file, delimiter=',')\n",
    "            writer.writerow(['Name','Discount','Tag','Original_Price','Discount_Price','Deadline'])\n",
    "\n",
    "main='https://www.dekudeals.com/'\n",
    "link_list=[]\n",
    "headers={'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36'}\n",
    "for i in range(4,7):\n",
    "    link_list.append(main+'hottest?page='+str(i))\n",
    "    \n",
    "startTime=time.time()\n",
    "for link,ip in zip(link_list,useble_lst):\n",
    "    response=requests.get(link,headers=headers,proxies={'http': ip})\n",
    "    soup=BeautifulSoup(response.text,'html.parser')\n",
    "    \n",
    "    games=soup.find_all('div',{'class':'cell'})\n",
    "    games\n",
    "    for game in games:\n",
    "        describe=game.find('div',{'class':'h6 name'}).text.strip()\n",
    "        name=[]\n",
    "        discount=[]\n",
    "        tag=[]\n",
    "        original_price=[]\n",
    "        discount_price=[]\n",
    "        deadline=[]\n",
    "        try:\n",
    "            describe.split('\\n')[0]\n",
    "            name=describe.split('\\n')[0]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            describe.split('\\n')[1]\n",
    "            discount=describe.split('\\n')[1]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            describe.split('\\n')[2]\n",
    "            tag=describe.split('\\n')[2]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            original_price=game.find('s',{'class':'text-muted'}).text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            discount_price=game.find('strong').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            deadline=game.find('div',{'class':'w-100'}).find('small').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        with open('sgp_4-6.csv',\"a+\",encoding='utf-8') as file:\n",
    "            writer = csv.writer(file, delimiter=',')\n",
    "            writer.writerow([name,discount,tag,original_price,discount_price,deadline])\n",
    "            \n",
    "finishTime = time.time()\n",
    "print(finishTime - startTime,'secs spend to craw these 3 pages')\n",
    "\n",
    "filechecker('sgp_4-6.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutiple thread\n",
    "-3thread for crawlering the number 7-9 pages of switch game price info. in hottest order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swg_crawler(link_list,filename):\n",
    "    with open(filename,\"a+\",encoding='utf-8') as file:\n",
    "            writer = csv.writer(file, delimiter=',')\n",
    "            writer.writerow(['Name','Discount','Tag','Original_Price','Discount_Price','Deadline'])\n",
    "    \n",
    "    for link in link_list:\n",
    "        response=requests.get(link)\n",
    "        soup=BeautifulSoup(response.text,'html.parser')\n",
    "    \n",
    "        games=soup.find_all('div',{'class':'cell'})\n",
    "        games\n",
    "        for game in games:\n",
    "            describe=game.find('div',{'class':'h6 name'}).text.strip()\n",
    "            name=[]\n",
    "            discount=[]\n",
    "            tag=[]\n",
    "            original_price=[]\n",
    "            discount_price=[]\n",
    "            deadline=[]\n",
    "            try:\n",
    "                describe.split('\\n')[0]\n",
    "                name=describe.split('\\n')[0]\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                describe.split('\\n')[1]\n",
    "                discount=describe.split('\\n')[1]\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                describe.split('\\n')[2]\n",
    "                tag=describe.split('\\n')[2]\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                original_price=game.find('s',{'class':'text-muted'}).text.strip()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                discount_price=game.find('strong').text.strip()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                deadline=game.find('div',{'class':'w-100'}).find('small').text.strip()\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "            with open(filename,\"a+\",encoding='utf-8') as file:\n",
    "                writer = csv.writer(file, delimiter=',')\n",
    "                writer.writerow([name,discount,tag,original_price,discount_price,deadline])\n",
    "    \n",
    "    filechecker(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['https://www.dekudeals.com/hottest?page=7', 'https://www.dekudeals.com/hottest?page=8', 'https://www.dekudeals.com/hottest?page=9'], ['https://www.dekudeals.com/hottest?page=10', 'https://www.dekudeals.com/hottest?page=11']]\n"
     ]
    }
   ],
   "source": [
    "link_list7=[]\n",
    "link_list9=[]\n",
    "link_list_large=[]\n",
    "for i in range(7,10):\n",
    "    link_list7.append(main+'hottest?page='+str(i))\n",
    "for i in range(10,12):\n",
    "    link_list9.append(main+'hottest?page='+str(i))\n",
    "\n",
    "link_list_large.append(link_list7)\n",
    "link_list_large.append(link_list9)\n",
    "\n",
    "print(link_list_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001709461212158203 secs spend to craw these 5 pages\n"
     ]
    }
   ],
   "source": [
    "startTime=time.time()\n",
    "\n",
    "for link_list,n in zip(link_list_large,[7,9]):\n",
    "    _thread.start_new_thread(swg_crawler,(link_list,'sgp_{0}.csv'.format(str(n)) ))\n",
    "    \n",
    "finishTime = time.time()\n",
    "print(finishTime - startTime,'secs spend to craw these 5 pages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asynchronous Crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp \n",
    "import asyncio \n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the largest page number\n",
    "link='https://www.dekudeals.com/hottest?page=1'\n",
    "r=requests.get(link)\n",
    "soup=BeautifulSoup(r.text,'html5lib')\n",
    "maxpage=int(soup.find_all('a',{'class':'page-link'})[-2].text)+1\n",
    "maxpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swg_crawler_single(link,filename='asyncio.csv'):\n",
    "    response=requests.get(link)\n",
    "    soup=BeautifulSoup(response.text,'html.parser')\n",
    "    \n",
    "    games=soup.find_all('div',{'class':'cell'})\n",
    "    games\n",
    "    for game in games:\n",
    "        describe=game.find('div',{'class':'h6 name'}).text.strip()\n",
    "        name=[]\n",
    "        discount=[]\n",
    "        tag=[]\n",
    "        original_price=[]\n",
    "        discount_price=[]\n",
    "        deadline=[]\n",
    "        try:\n",
    "            describe.split('\\n')[0]\n",
    "            name=describe.split('\\n')[0]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            describe.split('\\n')[1]\n",
    "            discount=describe.split('\\n')[1]\n",
    "        except:\n",
    "              pass\n",
    "        try:\n",
    "            describe.split('\\n')[2]\n",
    "            tag=describe.split('\\n')[2]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            original_price=game.find('s',{'class':'text-muted'}).text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            discount_price=game.find('strong').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            deadline=game.find('div',{'class':'w-100'}).find('small').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "        with open(filename,\"a+\",encoding='utf-8') as file:\n",
    "            writer = csv.writer(file, delimiter=',')\n",
    "            writer.writerow([name,discount,tag,original_price,discount_price,deadline])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 5 of 217 rows from sgp_7.csv data\n",
      "                                         Name Discount                   Tag  \\\n",
      "0  LEGO Marvel Super Heroes 2 Deluxe Edition     -70%  Matches previous low   \n",
      "1                                 1-2-Switch     -28%                    []   \n",
      "2                        Stick It to The Man     -80%  Matches previous low   \n",
      "3                      Wide Ocean Big Jacket     -60%  Matches previous low   \n",
      "4                 Call of Juarez: Gunslinger     -40%                    []   \n",
      "\n",
      "  Original_Price Discount_Price              Deadline  \n",
      "0         $44.99         $13.49  Sale ends November 2  \n",
      "1         $49.99         $35.88                    []  \n",
      "2         $11.99          $2.39  Sale ends November 1  \n",
      "3          $7.99          $3.19  Sale ends November 1  \n",
      "4         $19.99         $11.99  Sale ends November 3  \n",
      "top 5 of 145 rows from sgp_9.csv data\n",
      "                          Name Discount                   Tag Original_Price  \\\n",
      "0  Super Mutant Alien Assault     -80%  Matches previous low          $9.99   \n",
      "1                   Unrailed!     -25%     Lowest price ever         $19.99   \n",
      "2              Stories Untold     -50%                    []          $9.99   \n",
      "3        The Raven Remastered     -50%                    []         $29.99   \n",
      "4             In Other Waters     -25%  Matches previous low         $14.99   \n",
      "\n",
      "  Discount_Price               Deadline  \n",
      "0          $1.99   Sale ends November 2  \n",
      "1         $14.99  Sale ends November 12  \n",
      "2          $4.99   Sale ends November 2  \n",
      "3         $14.99   Sale ends November 5  \n",
      "4         $11.24   Sale ends November 2  \n",
      "Async total time :  19.881837606430054\n",
      "top 5 of 1113 rows from asyncio.csv data\n",
      "                                       Name Discount                   Tag  \\\n",
      "0                              Moonlighter     -66%  Matches previous low   \n",
      "1  Ghostbusters: The Video Game Remastered     -75%     Lowest price ever   \n",
      "2                                Cat Quest     -85%     Lowest price ever   \n",
      "3                               Bloodroots     -90%     Lowest price ever   \n",
      "4                 BioShock: The Collection     -40%     Lowest price ever   \n",
      "\n",
      "  Original_Price Discount_Price               Deadline  \n",
      "0         $24.99          $8.49   Sale ends October 31  \n",
      "1         $29.99          $7.49   Sale ends November 2  \n",
      "2         $12.99          $1.99  Sale ends in 38 hours  \n",
      "3         $19.99          $1.99   Sale ends November 2  \n",
      "4         $49.99         $29.83                     []  \n"
     ]
    }
   ],
   "source": [
    "with open('asyncio.csv',\"a+\",encoding='utf-8') as file:\n",
    "            writer = csv.writer(file, delimiter=',')\n",
    "            writer.writerow(['Name','Discount','Tag','Original_Price','Discount_Price','Deadline'])\n",
    "\n",
    "main='https://www.dekudeals.com/'\n",
    "link_list=[]\n",
    "for i in range(1,maxpage):\n",
    "    link_list.append(main+'hottest?page='+str(i)) \n",
    "    \n",
    "n=0\n",
    "async def job(link):                   # async 形式的功能\n",
    "    swg_crawler_single(link)\n",
    "    await asyncio.sleep(0)           #等待數秒並切換  #也可移除表不等待\n",
    "    \n",
    "\n",
    "async def main(loop):                       # async 形式的功能\n",
    "    tasks = [loop.create_task(job(link)) for link in link_list]    # 創建任務, 但是不執行\n",
    "    await asyncio.wait(tasks)               # 執行並等待所有任務完成\n",
    "\n",
    "startTime = time.time()\n",
    "loop = asyncio.get_event_loop()             # 建立 loop\n",
    "loop.run_until_complete(main(loop))         # 執行 loop                        \n",
    "#loop.close() #關閉 loop\n",
    "\n",
    "finishTime=time.time()\n",
    "print(\"Async total time : \", finishTime - startTime)\n",
    "filechecker('asyncio.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single time :  14.475460052490234\n",
      "top 5 of 557 rows from single.csv data\n",
      "                                       Name Discount                   Tag  \\\n",
      "0                              Moonlighter     -66%  Matches previous low   \n",
      "1  Ghostbusters: The Video Game Remastered     -75%     Lowest price ever   \n",
      "2                                Cat Quest     -85%     Lowest price ever   \n",
      "3                               Bloodroots     -90%     Lowest price ever   \n",
      "4                 BioShock: The Collection     -40%     Lowest price ever   \n",
      "\n",
      "  Original_Price Discount_Price               Deadline  \n",
      "0         $24.99          $8.49   Sale ends October 31  \n",
      "1         $29.99          $7.49   Sale ends November 2  \n",
      "2         $12.99          $1.99  Sale ends in 38 hours  \n",
      "3         $19.99          $1.99   Sale ends November 2  \n",
      "4         $49.99         $29.83                     []  \n"
     ]
    }
   ],
   "source": [
    "with open('single.csv',\"a+\",encoding='utf-8') as file:\n",
    "            writer = csv.writer(file, delimiter=',')\n",
    "            writer.writerow(['Name','Discount','Tag','Original_Price','Discount_Price','Deadline'])\n",
    "            \n",
    "main='https://www.dekudeals.com/'\n",
    "link_list=[]\n",
    "for i in range(1,maxpage):\n",
    "    link_list.append(main+'hottest?page='+str(i)) \n",
    "\n",
    "startTime=time.time()    \n",
    "for link in link_list:\n",
    "    swg_crawler_single(link,filename='single.csv')\n",
    "    \n",
    "    \n",
    "finishTime=time.time()\n",
    "print(\"Single time : \", finishTime - startTime)\n",
    "filechecker('single.csv')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutiple thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.809208154678345 secs spend to craw these 11 pages\n",
      "top 5 of 1114 rows from muti_thread.csv data\n",
      "                                       Name Discount                   Tag  \\\n",
      "0                              Moonlighter     -66%  Matches previous low   \n",
      "1  Ghostbusters: The Video Game Remastered     -75%     Lowest price ever   \n",
      "2                                Cat Quest     -85%     Lowest price ever   \n",
      "3                               Bloodroots     -90%     Lowest price ever   \n",
      "4                 BioShock: The Collection     -40%     Lowest price ever   \n",
      "\n",
      "  Original_Price Discount_Price               Deadline  \n",
      "0         $24.99          $8.49   Sale ends October 31  \n",
      "1         $29.99          $7.49   Sale ends November 2  \n",
      "2         $12.99          $1.99  Sale ends in 38 hours  \n",
      "3         $19.99          $1.99   Sale ends November 2  \n",
      "4         $49.99         $29.83                     []  \n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "with open('muti_thread.csv',\"a+\",encoding='utf-8') as file:\n",
    "            writer = csv.writer(file, delimiter=',')\n",
    "            writer.writerow(['Name','Discount','Tag','Original_Price','Discount_Price','Deadline'])\n",
    "\n",
    "main='https://www.dekudeals.com/'\n",
    "link_list=[]\n",
    "for i in range(1,maxpage):\n",
    "    link_list.append(main+'hottest?page='+str(i)) \n",
    "\n",
    "\n",
    "startTime=time.time()\n",
    "\n",
    "threads=[]\n",
    "#build all the tasks \n",
    "for link in link_list:\n",
    "    thread = threading.Thread(target=swg_crawler_single,args=(link,'muti_thread.csv'))\n",
    "    threads.append(thread) \n",
    "    \n",
    "#start all the tasks at once\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "    \n",
    "#wait for all the tasks to finish\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "    \n",
    "finishTime = time.time()\n",
    "print(finishTime - startTime,'secs spend to craw these 11 pages')\n",
    "filechecker('muti_thread.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save game photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 557 images saved\n"
     ]
    }
   ],
   "source": [
    "# path\n",
    "output_dir = 'image'\n",
    "\n",
    "# if not exist, create one\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "#link list\n",
    "main='https://www.dekudeals.com/'\n",
    "link_list=[]\n",
    "for i in range(1,maxpage):\n",
    "    link_list.append(main+'hottest?page='+str(i))     \n",
    "\n",
    "n=0 \n",
    "for link in link_list:\n",
    "   \n",
    "    #image_tag\n",
    "    response=requests.get(link)\n",
    "    soup=BeautifulSoup(response.text,'html.parser')\n",
    "    items=soup.find_all('div',{'class':'col-xl-2'})\n",
    "    for item in items:\n",
    "        try:\n",
    "            describe=item.find('div',{'class':'name'}).text.strip()\n",
    "            name=describe.split('\\n')[0].replace('/',',')\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            image_link=item.find('img')['src']\n",
    "        except:\n",
    "            pass\n",
    "        with requests.get(image_link, stream=True) as r:\n",
    "            n=n+1\n",
    "            r.raise_for_status()#check status\n",
    "            # check format\n",
    "            img = Image.open(r.raw)#format\n",
    "            img_savename = '{outdir}/{img_id}.{img_ext}'.format(\n",
    "                outdir=output_dir, img_id=name, img_ext=img.format.lower())\n",
    "            img.save(img_savename)\n",
    "        #print('Save image {}'.format(img_savename))\n",
    "        \n",
    "print('Total',n,'images saved')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 of 557 game images\n",
      " ['CARRION.jpeg', 'LEGO Harry Potter Collection.jpeg', 'AER Memories of Old.jpeg', 'RIVE: Ultimate Edition.jpeg', 'Cars 3: Driven to Win.jpeg']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "imagefiles = []\n",
    "for file in glob.glob(\"image/*.jpeg\"):\n",
    "    imagefiles.append(file.replace('image/',''))\n",
    "for file in glob.glob('image/*.png'):\n",
    "    imagefiles.append(file.replace('image/',''))\n",
    "\n",
    "print('Top 5 of {0} game images\\n'.format(len(imagefiles)),imagefiles[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all the options for searching game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome(executable_path='chromedriver')\n",
    "browser.get(\"https://www.dekudeals.com/hottest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Games': 'games',\n",
       " 'Hardware': 'hardware',\n",
       " 'DLC': 'dlc',\n",
       " 'Hottest Deals': 'hottest',\n",
       " 'Recent Price Drops': 'recent-drops',\n",
       " 'eShop Sales': 'eshop-sales',\n",
       " 'Bang for your Buck': 'bang-for-your-buck',\n",
       " 'Ending Soon': 'ending-soon',\n",
       " 'Most Wanted': 'most-wanted',\n",
       " 'Upcoming Releases': 'upcoming-releases',\n",
       " 'Recently Released': 'recently-released',\n",
       " 'Highly Rated': 'highest-rated',\n",
       " \"Michael's Picks\": 'michaels-picks',\n",
       " 'Deepest Discounts': 'deepest-discounts',\n",
       " 'Newly Listed': 'newest-listings'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_source = browser.page_source\n",
    "soup=BeautifulSoup(html_source,'html.parser')\n",
    "sorts=soup.find_all('li',{'class':'dropdown'})[0].find('div',{'class':'dropdown-menu'})\n",
    "sort_dict={}\n",
    "for sort in sorts:\n",
    "    try:\n",
    "        sort_dict.update({sort.text:sort['href'][1:]})\n",
    "    except:\n",
    "        pass\n",
    "sort_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Games': 'games',\n",
       " 'Hottest Deals': 'hottest',\n",
       " 'Recent Price Drops': 'recent-drops',\n",
       " 'eShop Sales': 'eshop-sales',\n",
       " 'Bang for your Buck': 'bang-for-your-buck',\n",
       " 'Ending Soon': 'ending-soon',\n",
       " 'Most Wanted': 'most-wanted',\n",
       " 'Upcoming Releases': 'upcoming-releases',\n",
       " 'Recently Released': 'recently-released',\n",
       " 'Highly Rated': 'highest-rated',\n",
       " \"Michael's Picks\": 'michaels-picks',\n",
       " 'Deepest Discounts': 'deepest-discounts',\n",
       " 'Newly Listed': 'newest-listings'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_dict.pop('Hardware')\n",
    "sort_dict.pop('DLC')\n",
    "sort_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.dekudeals.com/games\n",
      "In Games type the top 5 game:['Moonlighter', 'Ghostbusters: The Video Game Remastered', 'Cat Quest', 'Bloodroots', 'BioShock: The Collection']\n",
      "\n",
      "https://www.dekudeals.com/hottest\n",
      "In Hottest Deals type the top 5 game:['Moonlighter', 'Ghostbusters: The Video Game Remastered', 'Cat Quest', 'Bloodroots', 'BioShock: The Collection']\n",
      "\n",
      "https://www.dekudeals.com/recent-drops\n",
      "In Recent Price Drops type the top 5 game:['Save Your Nuts', 'Food Truck Tycoon - Asian Cuisine Complete Edition', 'Georifters', 'Rapala Fishing Pro Series', 'Cartoon Network: Battle Crashers']\n",
      "\n",
      "https://www.dekudeals.com/eshop-sales\n",
      "In eShop Sales type the top 5 game:['Moonlighter', 'Ghostbusters: The Video Game Remastered', 'Cat Quest', 'Bloodroots', 'Child of Light Ultimate Edition']\n",
      "\n",
      "https://www.dekudeals.com/bang-for-your-buck\n",
      "In Bang for your Buck type the top 5 game:['Super Chariot', \"Don't Starve: Nintendo Switch Edition\", 'Overwatch: Legendary Edition', 'Enter the Gungeon', 'Monster Hunter Generations Ultimate']\n",
      "\n",
      "https://www.dekudeals.com/ending-soon\n",
      "In Ending Soon type the top 5 game:['Tower of Babel - no mercy', 'WWE 2K Battlegrounds Digital Deluxe Edition', 'Wuppo: Definitive Edition', 'WWE 2K Battlegrounds', 'Venture Kid']\n",
      "\n",
      "https://www.dekudeals.com/most-wanted\n",
      "In Most Wanted type the top 5 game:['The Legend of Zelda: Link’s Awakening', 'Luigi’s Mansion 3', 'Super Mario Odyssey', 'Mario Kart 8 Deluxe', 'Donkey Kong Country: Tropical Freeze']\n",
      "\n",
      "https://www.dekudeals.com/upcoming-releases\n",
      "In Upcoming Releases type the top 5 game:['#Halloween, Super Puzzles Dream', 'Barbearian', 'Crimzon Clover - World EXplosion', 'De: Yabatanien', 'Demong Hunter']\n",
      "\n",
      "https://www.dekudeals.com/recently-released\n",
      "In Recently Released type the top 5 game:['Chickens Madness', 'Control Ultimate Edition - Cloud Version', 'Gibbous - A Cthulhu Adventure', 'No More Heroes', 'No More Heroes 2: Desperate Struggle']\n",
      "\n",
      "https://www.dekudeals.com/highest-rated\n",
      "In Highly Rated type the top 5 game:['Super Mario Odyssey', 'The Legend of Zelda: Breath of the Wild', 'Hades', 'Ori and the Will of the Wisps', 'Divinity: Original Sin 2 - Definitive Edition']\n",
      "\n",
      "https://www.dekudeals.com/michaels-picks\n",
      "In Michael's Picks type the top 5 game:['Crypt of the NecroDancer: Nintendo Switch Edition', 'Pipe Push Paradise', 'Mario + Rabbids Kingdom Battle', 'Human Resource Machine', 'Splatoon 2']\n",
      "\n",
      "https://www.dekudeals.com/deepest-discounts\n",
      "In Deepest Discounts type the top 5 game:['Ludomania', 'The Rainsdowne Players', 'Goonya Fighter', 'Flowlines VS', 'Syberia 2']\n",
      "\n",
      "https://www.dekudeals.com/newest-listings\n",
      "In Newly Listed type the top 5 game:['STORY OF SEASONS: Pioneers of Olive Town', 'Surviving the Aftermath', 'Griftlands', 'Tropico 6 - Nintendo Switch Edition', 'Immortals Fenyx Rising']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sort in sort_dict:\n",
    "    browser.get(\"https://www.dekudeals.com/{0}\".format(sort_dict.get(sort)))\n",
    "    html_source = browser.page_source\n",
    "    print(browser.current_url)\n",
    "    soup=BeautifulSoup(html_source,'html.parser')\n",
    "    games=soup.find_all('div',{'class':'cell'})[:5]\n",
    "    game_list=[]\n",
    "    for game in games:\n",
    "        describe=game.find('div',{'class':'h6 name'}).text.strip()\n",
    "        name=[]\n",
    "        discount=[]\n",
    "        tag=[]\n",
    "        original_price=[]\n",
    "        discount_price=[]\n",
    "        deadline=[]\n",
    "        try:\n",
    "            describe.split('\\n')[0]\n",
    "            name=describe.split('\\n')[0]\n",
    "        except:\n",
    "            pass\n",
    "        game_list.append(name)\n",
    "    print('In {0} type the top 5 game:{1}\\n'.format(sort,game_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
